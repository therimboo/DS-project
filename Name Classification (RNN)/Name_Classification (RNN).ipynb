{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a0aa09",
   "metadata": {},
   "source": [
    "# Name Classification Using RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8899cbd",
   "metadata": {},
   "source": [
    "<p>Salam Alikom everyone, In this project we're going to make a classification model using RNN with Pytorch framework.<br>\n",
    "So the model's role is to classify a name, which language that the name belongs to. We have 18 different languages <i>(Arabic, English, French, etc...)</i>.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd8a760",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd261fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import unicodedata\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4fa7c8",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d54c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_LETTERS = string.ascii_letters + \" .,;'\"\n",
    "N_LETTERS = len(ALL_LETTERS)\n",
    "DATA_FOLDER = \"./data/names/\"\n",
    "FILE_NAMES = os.listdir(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c446f8fc",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a104a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(name):\n",
    "    return ''.join(\n",
    "    c for c in unicodedata.normalize('NFD', name)\n",
    "    if unicodedata.category(c) != 'Mn'\n",
    "    and c in ALL_LETTERS\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ba11c",
   "metadata": {},
   "source": [
    "#### Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae7272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "languages = []\n",
    "\n",
    "for file_name in FILE_NAMES:\n",
    "    file_path = os.path.join(DATA_FOLDER, file_name)\n",
    "    with open(file_path, 'r', encoding='utf8') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            name = line.strip()\n",
    "            name = unicode_to_ascii(name)\n",
    "            language = file_name.split('.')[0]\n",
    "            languages.append(language) if language not in languages else None\n",
    "            data.append([[letter for letter in name], language])\n",
    "language_label = {language: index for index, language in enumerate(languages)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d09671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 18 different laguanges\n",
    "language_label.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67c59b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = [l for l in language_label.keys()]\n",
    "labels_count = []\n",
    "for label in labels_list:\n",
    "    count = 0\n",
    "    count = sum(1 for _, y in data if y == label)\n",
    "    labels_count.append([label, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3fe0807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Arabic', 2000],\n",
       " ['Chinese', 268],\n",
       " ['Czech', 519],\n",
       " ['Dutch', 297],\n",
       " ['English', 3668],\n",
       " ['French', 277],\n",
       " ['German', 724],\n",
       " ['Greek', 203],\n",
       " ['Irish', 232],\n",
       " ['Italian', 709],\n",
       " ['Japanese', 991],\n",
       " ['Korean', 94],\n",
       " ['Polish', 139],\n",
       " ['Portuguese', 74],\n",
       " ['Russian', 9408],\n",
       " ['Scottish', 100],\n",
       " ['Spanish', 298],\n",
       " ['Vietnamese', 73]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9ddf094",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af1d9114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['M', 'a', 'l', 'a', 'f', 'a'], 'Czech'],\n",
       " [['K', 'a', 'l', 'a', 'm', 'k', 'a', 'r', 'y', 'a', 'n'], 'Russian'],\n",
       " [['K', 'o', 'u', 'r', 'i'], 'Arabic'],\n",
       " [['K', 'a', 'p', 'p', 'e', 'l'], 'German'],\n",
       " [['M', 'u', 's', 't', 'a', 'f', 'a'], 'Arabic'],\n",
       " [['F', 'i', 'o', 'h', 'i', 'n'], 'Russian'],\n",
       " [['D', 'u', 'b', 'n', 'i', 'k', 'o', 'v'], 'Russian'],\n",
       " [['S', 'h', 'a', 'l', 'a', 'g', 'a', 'e', 'v'], 'Russian'],\n",
       " [['J', 'u', 'k'], 'Russian'],\n",
       " [['K', 'a', 'l', 'i', 'n', 'k', 'o'], 'Russian']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55835920",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "006521cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = torch.eye(N_LETTERS)\n",
    "encoded_data = []\n",
    "for idx, name in enumerate(data):\n",
    "    encoded_name = []\n",
    "    for letter in name[0]:\n",
    "        encoded_name.append(one_hot[ALL_LETTERS.index(letter)])\n",
    "    encoded_data.append([encoded_name, language_label[name[1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0713e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding Tensors ==> To create a Tensor of Tensors instead of List of Tensors\n",
    "padded_tensor = pad_sequence([torch.stack(tensor) for tensor, _ in encoded_data],\n",
    "                             batch_first=True, padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5287ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_tensor[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da39d2d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X = data, y = Labels\n",
    "X = torch.stack([tensor for tensor in padded_tensor])\n",
    "y = torch.tensor([y for _, y in encoded_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7fb8fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20074, 20074)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()[0], y.size()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc426e3",
   "metadata": {},
   "source": [
    "#### Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24446ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee6248c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(dataset))  \n",
    "val_size = int(0.2 * len(dataset))    \n",
    "test_size = len(dataset) - train_size - val_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59033160",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4354f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a34c3ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: torch.Size([32, 19, 57])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "input_data, labels = batch\n",
    "\n",
    "print(\"Input data shape:\", input_data.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca36680",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa7a9e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "LR = 0.0001\n",
    "CLASSES = 18  # Number of classes\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53dc3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.rnn = nn.RNN(input_size, input_size*8, batch_first=True)\n",
    "        self.fc = nn.Linear(input_size*8, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.input_size*8).to(DEVICE)\n",
    "        out, _ = self.rnn(x, h0) \n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71b1918c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (rnn): GRU(57, 456, batch_first=True)\n",
       "  (fc): Linear(in_features=456, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(N_LETTERS, CLASSES)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e2a075",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db92e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0\n",
    "all_losses = []\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    # Create tqdm progress bar\n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "    \n",
    "    # Iterate over batches of training data\n",
    "    for batch_idx, (inputs, labels) in loop:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)   \n",
    "        \n",
    "        # 0 Grads\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Update tqdm progress bar\n",
    "        loop.set_description(f\"Epoch[{epoch}/{NUM_EPOCHS}]\")\n",
    "        loop.set_postfix(loss = loss.item())\n",
    "    \n",
    "    all_losses.append(running_loss)\n",
    "    \n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Accuracy = {accuracy}\")\n",
    "    \n",
    "    # Check if accuracy has improved\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), \"./models/best_model2_\"+str(epoch)+\".pth\")\n",
    "        print(\"Best model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80baa458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation loop\n",
    "model.eval()  # Set model to evaluation mode\n",
    "val_loss = 0.0\n",
    "val_correct_predictions = 0\n",
    "val_total_predictions = 0\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        val_total_predictions += labels.size(0)\n",
    "        val_correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss += loss.item()\n",
    "\n",
    "    val_accuracy = val_correct_predictions / val_total_predictions\n",
    "    print(f\"Validation Accuracy = {val_accuracy}\")\n",
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
